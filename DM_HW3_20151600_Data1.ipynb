{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"DM_HW3_20151600_Data1.ipynb","provenance":[{"file_id":"1UG0K5VkLbol9gj2c1IoRHGBpa-bw7WiY","timestamp":1587823553803},{"file_id":"1_oMj_NYXLn2gC9OdU-0WG2AwVzZV1UJK","timestamp":1587654371088}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"2IN9OeIfwFGa","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M8xp1PzfwFGe","colab_type":"text"},"source":["# Wine dataset 불러오기"]},{"cell_type":"code","metadata":{"id":"xTJ12aq6wFGf","colab_type":"code","outputId":"6631b3ff-a22b-4d2e-bc38-a9edf6c45d3b","executionInfo":{"status":"ok","timestamp":1587823900607,"user_tz":-540,"elapsed":1046,"user":{"displayName":"Seungmin Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrBDTQ8yuyAIB0J9i4gCDtr8Ku4cakCng55yF7=s64","userId":"12825424897417784138"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","\n","cancer = load_breast_cancer()\n","X_train, X_test, Y_train, Y_test = train_test_split(cancer.data, cancer.target, random_state=777, test_size=0.2)\n","print(X_train.shape)\n","print(X_test.shape)\n","print(Y_train.shape)\n","print(Y_test.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(455, 30)\n","(114, 30)\n","(455,)\n","(114,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Qp7Vw3OuwFGj","colab_type":"text"},"source":["# Wine dataset (참고용)"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"CW9DwU2wwFGk","colab_type":"code","outputId":"76ac7ce0-bfa5-4e5d-e669-7b354486ac1c","executionInfo":{"status":"ok","timestamp":1587823925502,"user_tz":-540,"elapsed":1025,"user":{"displayName":"Seungmin Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrBDTQ8yuyAIB0J9i4gCDtr8Ku4cakCng55yF7=s64","userId":"12825424897417784138"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n","sy = pd.Series(cancer.target, dtype=\"category\")\n","sy = sy.cat.rename_categories(cancer.target_names)\n","df['class'] = sy\n","print(digit.DESCR)\n","df.head()"],"execution_count":7,"outputs":[{"output_type":"stream","text":[".. _digits_dataset:\n","\n","Optical recognition of handwritten digits dataset\n","--------------------------------------------------\n","\n","**Data Set Characteristics:**\n","\n","    :Number of Instances: 5620\n","    :Number of Attributes: 64\n","    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n","    :Missing Attribute Values: None\n","    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n","    :Date: July; 1998\n","\n","This is a copy of the test set of the UCI ML hand-written digits datasets\n","https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n","\n","The data set contains images of hand-written digits: 10 classes where\n","each class refers to a digit.\n","\n","Preprocessing programs made available by NIST were used to extract\n","normalized bitmaps of handwritten digits from a preprinted form. From a\n","total of 43 people, 30 contributed to the training set and different 13\n","to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n","4x4 and the number of on pixels are counted in each block. This generates\n","an input matrix of 8x8 where each element is an integer in the range\n","0..16. This reduces dimensionality and gives invariance to small\n","distortions.\n","\n","For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n","T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n","L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n","1994.\n","\n",".. topic:: References\n","\n","  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n","    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n","    Graduate Studies in Science and Engineering, Bogazici University.\n","  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n","  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n","    Linear dimensionalityreduction using relevance weighted LDA. School of\n","    Electrical and Electronic Engineering Nanyang Technological University.\n","    2005.\n","  - Claudio Gentile. A New Approximate Maximal Margin Classification\n","    Algorithm. NIPS. 2000.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean radius</th>\n","      <th>mean texture</th>\n","      <th>mean perimeter</th>\n","      <th>mean area</th>\n","      <th>mean smoothness</th>\n","      <th>mean compactness</th>\n","      <th>mean concavity</th>\n","      <th>mean concave points</th>\n","      <th>mean symmetry</th>\n","      <th>mean fractal dimension</th>\n","      <th>radius error</th>\n","      <th>texture error</th>\n","      <th>perimeter error</th>\n","      <th>area error</th>\n","      <th>smoothness error</th>\n","      <th>compactness error</th>\n","      <th>concavity error</th>\n","      <th>concave points error</th>\n","      <th>symmetry error</th>\n","      <th>fractal dimension error</th>\n","      <th>worst radius</th>\n","      <th>worst texture</th>\n","      <th>worst perimeter</th>\n","      <th>worst area</th>\n","      <th>worst smoothness</th>\n","      <th>worst compactness</th>\n","      <th>worst concavity</th>\n","      <th>worst concave points</th>\n","      <th>worst symmetry</th>\n","      <th>worst fractal dimension</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.3001</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>0.07871</td>\n","      <td>1.0950</td>\n","      <td>0.9053</td>\n","      <td>8.589</td>\n","      <td>153.40</td>\n","      <td>0.006399</td>\n","      <td>0.04904</td>\n","      <td>0.05373</td>\n","      <td>0.01587</td>\n","      <td>0.03003</td>\n","      <td>0.006193</td>\n","      <td>25.38</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.1622</td>\n","      <td>0.6656</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","      <td>malignant</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.0869</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>0.5435</td>\n","      <td>0.7339</td>\n","      <td>3.398</td>\n","      <td>74.08</td>\n","      <td>0.005225</td>\n","      <td>0.01308</td>\n","      <td>0.01860</td>\n","      <td>0.01340</td>\n","      <td>0.01389</td>\n","      <td>0.003532</td>\n","      <td>24.99</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.1238</td>\n","      <td>0.1866</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","      <td>malignant</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.1974</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>0.7456</td>\n","      <td>0.7869</td>\n","      <td>4.585</td>\n","      <td>94.03</td>\n","      <td>0.006150</td>\n","      <td>0.04006</td>\n","      <td>0.03832</td>\n","      <td>0.02058</td>\n","      <td>0.02250</td>\n","      <td>0.004571</td>\n","      <td>23.57</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.1444</td>\n","      <td>0.4245</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","      <td>malignant</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.2414</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>0.4956</td>\n","      <td>1.1560</td>\n","      <td>3.445</td>\n","      <td>27.23</td>\n","      <td>0.009110</td>\n","      <td>0.07458</td>\n","      <td>0.05661</td>\n","      <td>0.01867</td>\n","      <td>0.05963</td>\n","      <td>0.009208</td>\n","      <td>14.91</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.2098</td>\n","      <td>0.8663</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","      <td>malignant</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.1980</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>0.7572</td>\n","      <td>0.7813</td>\n","      <td>5.438</td>\n","      <td>94.44</td>\n","      <td>0.011490</td>\n","      <td>0.02461</td>\n","      <td>0.05688</td>\n","      <td>0.01885</td>\n","      <td>0.01756</td>\n","      <td>0.005115</td>\n","      <td>22.54</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.1374</td>\n","      <td>0.2050</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","      <td>malignant</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   mean radius  mean texture  ...  worst fractal dimension      class\n","0        17.99         10.38  ...                  0.11890  malignant\n","1        20.57         17.77  ...                  0.08902  malignant\n","2        19.69         21.25  ...                  0.08758  malignant\n","3        11.42         20.38  ...                  0.17300  malignant\n","4        20.29         14.34  ...                  0.07678  malignant\n","\n","[5 rows x 31 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"YiRLeTwYwFGn","colab_type":"text"},"source":["# # Problem 1\n","ID3 Decision Tree classifier.\n","- decision-tree-id3 패키지를 pip install을 통해 설치하시오.\n","- 위의 train 데이터(X_train, Y_train)를 이용하여 ID3 classifier 모델을 학습시키시오.\n","- 위의 test 데이터(X_test, Y_test)를 이용해 정확도를 측정 후 출력하시오."]},{"cell_type":"code","metadata":{"id":"Z-GeqATKwFGn","colab_type":"code","outputId":"e206af67-ec30-44f3-95bd-1e1652e09905","executionInfo":{"status":"ok","timestamp":1587823938605,"user_tz":-540,"elapsed":7265,"user":{"displayName":"Seungmin Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrBDTQ8yuyAIB0J9i4gCDtr8Ku4cakCng55yF7=s64","userId":"12825424897417784138"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["##########Put your installation code here###############\n","!pip install decision-tree-id3\n","########################################################"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Collecting decision-tree-id3\n","  Downloading https://files.pythonhosted.org/packages/53/60/9b51eb3b5096afa1fce2718f56c99f8e183162dae114c56592112ab54329/decision-tree-id3-0.1.2.tar.gz\n","Collecting nose>=1.1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n","\u001b[K     |████████████████████████████████| 163kB 9.5MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from decision-tree-id3) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from decision-tree-id3) (1.18.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17->decision-tree-id3) (0.14.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17->decision-tree-id3) (1.4.1)\n","Building wheels for collected packages: decision-tree-id3\n","  Building wheel for decision-tree-id3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for decision-tree-id3: filename=decision_tree_id3-0.1.2-cp36-none-any.whl size=15962 sha256=363a89695cdebdfe4eb033488e8ed83a861db4a615499bafb8a57fc47030a68d\n","  Stored in directory: /root/.cache/pip/wheels/2d/d6/f2/96cb2cc307503a88b1235aef5c794990e460bd044f382070f9\n","Successfully built decision-tree-id3\n","Installing collected packages: nose, decision-tree-id3\n","Successfully installed decision-tree-id3-0.1.2 nose-1.3.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SxJFP7QJwFGq","colab_type":"code","outputId":"74d05055-99e9-49cd-b947-c53f57fe5565","executionInfo":{"status":"ok","timestamp":1587823941381,"user_tz":-540,"elapsed":2545,"user":{"displayName":"Seungmin Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrBDTQ8yuyAIB0J9i4gCDtr8Ku4cakCng55yF7=s64","userId":"12825424897417784138"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["from id3 import Id3Estimator\n","\n","ID3_model = None\n","accuracy = None\n","############# Put your code here ################\n","ID3_model = Id3Estimator()\n","ID3_model.fit(X_train, Y_train)\n","test=ID3_model.predict(X_test)\n","accuracy=0;\n","per=1/len(test)\n","for i in range(len(test)):\n","  if test[i]==Y_test[i]:\n","    accuracy+=per\n","################################################# \n","print('Test data prediction accuracy (ID3) : %f'%accuracy)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n","  \"(https://pypi.org/project/six/).\", FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Test data prediction accuracy (ID3) : 0.929825\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4adJrG4KwFGu","colab_type":"text"},"source":["# # Problem 2\n","CART decision Tree classifier.\n","- scikit-learn의 decision tree는 CART 기반 구현체이다.\n","- Problem 1과 같은 방법으로 CART classifier 모델을 학습시키고 test데이터의 정확도를 출력하시오."]},{"cell_type":"code","metadata":{"id":"xub7uYdEwFGu","colab_type":"code","outputId":"6baa77bb-b21a-4e41-b557-244ef97533ca","executionInfo":{"status":"ok","timestamp":1587823945627,"user_tz":-540,"elapsed":1133,"user":{"displayName":"Seungmin Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrBDTQ8yuyAIB0J9i4gCDtr8Ku4cakCng55yF7=s64","userId":"12825424897417784138"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","CART_model = None\n","accuracy = None\n","############# Put your code here ################\n","CART_model = DecisionTreeClassifier(random_state=0)\n","CART_model.fit(X_train, Y_train)\n","accuracy=CART_model.score(X_test, Y_test)\n","################################################# \n","print('Test data prediction accuracy (CART) : %f'%accuracy)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Test data prediction accuracy (CART) : 0.912281\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u8YIUgHgwFGy","colab_type":"text"},"source":["# # Problem 3\n","Random Forest classifier.\n","- scikit-learn의 random forest 패키지를 이용하여 모델을 학습시키고 test데이터의 정확도를 출력하시오."]},{"cell_type":"code","metadata":{"id":"Dl2sukc2wFGy","colab_type":"code","outputId":"91a21cce-c97b-4b6f-dc39-4bec7748c61f","executionInfo":{"status":"ok","timestamp":1587823957106,"user_tz":-540,"elapsed":1182,"user":{"displayName":"Seungmin Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrBDTQ8yuyAIB0J9i4gCDtr8Ku4cakCng55yF7=s64","userId":"12825424897417784138"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","Random_Forest_model = None\n","accuracy = None\n","############# Put your code here ################\n","Random_Forest_model = RandomForestClassifier(random_state=0)\n","Random_Forest_model.fit(X_train,Y_train)\n","accuracy=Random_Forest_model.score(X_test, Y_test)\n","################################################# \n","print('Test data prediction accuracy (Random Forest) : %f'%accuracy)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Test data prediction accuracy (Random Forest) : 0.956140\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rvtrxXSuwFG2","colab_type":"text"},"source":["# # Problem 4\n","XGBoost classifier.\n","- XGBoost 패키지를 pip install을 통해 설치하시오.\n","- 패키지를 불러와 모델을 학습시키고 test데이터의 정확도를 출력하시오."]},{"cell_type":"code","metadata":{"id":"HsdVHPB8wFG2","colab_type":"code","outputId":"acb87097-5ba0-4694-f8b8-8b946b751e13","executionInfo":{"status":"ok","timestamp":1587823963363,"user_tz":-540,"elapsed":3972,"user":{"displayName":"Seungmin Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrBDTQ8yuyAIB0J9i4gCDtr8Ku4cakCng55yF7=s64","userId":"12825424897417784138"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["##########Put your installation code here###############\n","!pip install XGBoost\n","########################################################"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: XGBoost in /usr/local/lib/python3.6/dist-packages (0.90)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from XGBoost) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from XGBoost) (1.18.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xJ5d44CnwFG5","colab_type":"code","outputId":"dadbce9d-bb34-4823-d6be-8f2447768539","executionInfo":{"status":"ok","timestamp":1587823975645,"user_tz":-540,"elapsed":1164,"user":{"displayName":"Seungmin Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrBDTQ8yuyAIB0J9i4gCDtr8Ku4cakCng55yF7=s64","userId":"12825424897417784138"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import xgboost as xgb\n","\n","XGB_model = None\n","accuracy = None\n","############# Put your code here ################\n","XGB_model = xgb.XGBClassifier()\n","XGB_model.fit(X_train, Y_train)\n","test=XGB_model.predict(X_test)\n","accuracy=0;\n","per=1/len(test)\n","for i in range(len(test)):\n","  if test[i]==Y_test[i]:\n","    accuracy+=per\n","################################################# \n","print('Test data prediction accuracy (XGBoost) : %f'%accuracy)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Test data prediction accuracy (XGBoost) : 0.912281\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WmjWdOSOwFG-","colab_type":"text"},"source":["# # Problem 5\n","LightGBM classifier.\n","- LighGBM 패키지를 pip install을 통해 설치하시오.\n","- 패키지를 불러와 모델을 학습시키고 test데이터의 정확도를 출력하시오."]},{"cell_type":"code","metadata":{"id":"7IbrcMR3wFG-","colab_type":"code","outputId":"ab119076-5dbf-4386-ec9c-e8dbbf34cea6","executionInfo":{"status":"ok","timestamp":1587823981750,"user_tz":-540,"elapsed":4227,"user":{"displayName":"Seungmin Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrBDTQ8yuyAIB0J9i4gCDtr8Ku4cakCng55yF7=s64","userId":"12825424897417784138"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["##########Put your installation code here###############\n","!pip install LightGBM\n","########################################################"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: LightGBM in /usr/local/lib/python3.6/dist-packages (2.2.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from LightGBM) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from LightGBM) (0.22.2.post1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from LightGBM) (1.18.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->LightGBM) (0.14.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ow26Nbe9wFHB","colab_type":"code","outputId":"52798c46-cc0f-4c36-f3c9-ac42c1980c48","executionInfo":{"status":"ok","timestamp":1587823982923,"user_tz":-540,"elapsed":1168,"user":{"displayName":"Seungmin Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrBDTQ8yuyAIB0J9i4gCDtr8Ku4cakCng55yF7=s64","userId":"12825424897417784138"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import lightgbm as lgb\n","\n","LGBM_model = None\n","accuracy = None\n","############# Put your code here ################\n","LGBM_model = lgb.LGBMClassifier(n_estimators=200)\n","LGBM_model.fit(X_train,Y_train,early_stopping_rounds=100,eval_metric=\"logloss\",eval_set=[(X_test,Y_test)],verbose= True )\n","test = LGBM_model.predict(X_test)\n","accuracy=0;\n","per=1/len(test)\n","for i in range(len(test)):\n","  if test[i]==Y_test[i]:\n","    accuracy+=per\n","################################################# \n","print('Test data prediction accuracy (LightGBM) : %f'%accuracy)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[1]\tvalid_0's binary_logloss: 0.573283\tvalid_0's binary_logloss: 0.573283\n","Training until validation scores don't improve for 100 rounds.\n","[2]\tvalid_0's binary_logloss: 0.519484\tvalid_0's binary_logloss: 0.519484\n","[3]\tvalid_0's binary_logloss: 0.472958\tvalid_0's binary_logloss: 0.472958\n","[4]\tvalid_0's binary_logloss: 0.437086\tvalid_0's binary_logloss: 0.437086\n","[5]\tvalid_0's binary_logloss: 0.405053\tvalid_0's binary_logloss: 0.405053\n","[6]\tvalid_0's binary_logloss: 0.378001\tvalid_0's binary_logloss: 0.378001\n","[7]\tvalid_0's binary_logloss: 0.349636\tvalid_0's binary_logloss: 0.349636\n","[8]\tvalid_0's binary_logloss: 0.328866\tvalid_0's binary_logloss: 0.328866\n","[9]\tvalid_0's binary_logloss: 0.307363\tvalid_0's binary_logloss: 0.307363\n","[10]\tvalid_0's binary_logloss: 0.292376\tvalid_0's binary_logloss: 0.292376\n","[11]\tvalid_0's binary_logloss: 0.281797\tvalid_0's binary_logloss: 0.281797\n","[12]\tvalid_0's binary_logloss: 0.271082\tvalid_0's binary_logloss: 0.271082\n","[13]\tvalid_0's binary_logloss: 0.259612\tvalid_0's binary_logloss: 0.259612\n","[14]\tvalid_0's binary_logloss: 0.25173\tvalid_0's binary_logloss: 0.25173\n","[15]\tvalid_0's binary_logloss: 0.241625\tvalid_0's binary_logloss: 0.241625\n","[16]\tvalid_0's binary_logloss: 0.233496\tvalid_0's binary_logloss: 0.233496\n","[17]\tvalid_0's binary_logloss: 0.223434\tvalid_0's binary_logloss: 0.223434\n","[18]\tvalid_0's binary_logloss: 0.212992\tvalid_0's binary_logloss: 0.212992\n","[19]\tvalid_0's binary_logloss: 0.207085\tvalid_0's binary_logloss: 0.207085\n","[20]\tvalid_0's binary_logloss: 0.204694\tvalid_0's binary_logloss: 0.204694\n","[21]\tvalid_0's binary_logloss: 0.196492\tvalid_0's binary_logloss: 0.196492\n","[22]\tvalid_0's binary_logloss: 0.188869\tvalid_0's binary_logloss: 0.188869\n","[23]\tvalid_0's binary_logloss: 0.185771\tvalid_0's binary_logloss: 0.185771\n","[24]\tvalid_0's binary_logloss: 0.1815\tvalid_0's binary_logloss: 0.1815\n","[25]\tvalid_0's binary_logloss: 0.177481\tvalid_0's binary_logloss: 0.177481\n","[26]\tvalid_0's binary_logloss: 0.176751\tvalid_0's binary_logloss: 0.176751\n","[27]\tvalid_0's binary_logloss: 0.171862\tvalid_0's binary_logloss: 0.171862\n","[28]\tvalid_0's binary_logloss: 0.169088\tvalid_0's binary_logloss: 0.169088\n","[29]\tvalid_0's binary_logloss: 0.167853\tvalid_0's binary_logloss: 0.167853\n","[30]\tvalid_0's binary_logloss: 0.165817\tvalid_0's binary_logloss: 0.165817\n","[31]\tvalid_0's binary_logloss: 0.1663\tvalid_0's binary_logloss: 0.1663\n","[32]\tvalid_0's binary_logloss: 0.167167\tvalid_0's binary_logloss: 0.167167\n","[33]\tvalid_0's binary_logloss: 0.166896\tvalid_0's binary_logloss: 0.166896\n","[34]\tvalid_0's binary_logloss: 0.163782\tvalid_0's binary_logloss: 0.163782\n","[35]\tvalid_0's binary_logloss: 0.163107\tvalid_0's binary_logloss: 0.163107\n","[36]\tvalid_0's binary_logloss: 0.163779\tvalid_0's binary_logloss: 0.163779\n","[37]\tvalid_0's binary_logloss: 0.167294\tvalid_0's binary_logloss: 0.167294\n","[38]\tvalid_0's binary_logloss: 0.16771\tvalid_0's binary_logloss: 0.16771\n","[39]\tvalid_0's binary_logloss: 0.169786\tvalid_0's binary_logloss: 0.169786\n","[40]\tvalid_0's binary_logloss: 0.170198\tvalid_0's binary_logloss: 0.170198\n","[41]\tvalid_0's binary_logloss: 0.172318\tvalid_0's binary_logloss: 0.172318\n","[42]\tvalid_0's binary_logloss: 0.171757\tvalid_0's binary_logloss: 0.171757\n","[43]\tvalid_0's binary_logloss: 0.168579\tvalid_0's binary_logloss: 0.168579\n","[44]\tvalid_0's binary_logloss: 0.170106\tvalid_0's binary_logloss: 0.170106\n","[45]\tvalid_0's binary_logloss: 0.17209\tvalid_0's binary_logloss: 0.17209\n","[46]\tvalid_0's binary_logloss: 0.17026\tvalid_0's binary_logloss: 0.17026\n","[47]\tvalid_0's binary_logloss: 0.167794\tvalid_0's binary_logloss: 0.167794\n","[48]\tvalid_0's binary_logloss: 0.168795\tvalid_0's binary_logloss: 0.168795\n","[49]\tvalid_0's binary_logloss: 0.170252\tvalid_0's binary_logloss: 0.170252\n","[50]\tvalid_0's binary_logloss: 0.173167\tvalid_0's binary_logloss: 0.173167\n","[51]\tvalid_0's binary_logloss: 0.173273\tvalid_0's binary_logloss: 0.173273\n","[52]\tvalid_0's binary_logloss: 0.175\tvalid_0's binary_logloss: 0.175\n","[53]\tvalid_0's binary_logloss: 0.173341\tvalid_0's binary_logloss: 0.173341\n","[54]\tvalid_0's binary_logloss: 0.17511\tvalid_0's binary_logloss: 0.17511\n","[55]\tvalid_0's binary_logloss: 0.176981\tvalid_0's binary_logloss: 0.176981\n","[56]\tvalid_0's binary_logloss: 0.177904\tvalid_0's binary_logloss: 0.177904\n","[57]\tvalid_0's binary_logloss: 0.17948\tvalid_0's binary_logloss: 0.17948\n","[58]\tvalid_0's binary_logloss: 0.180136\tvalid_0's binary_logloss: 0.180136\n","[59]\tvalid_0's binary_logloss: 0.178558\tvalid_0's binary_logloss: 0.178558\n","[60]\tvalid_0's binary_logloss: 0.17572\tvalid_0's binary_logloss: 0.17572\n","[61]\tvalid_0's binary_logloss: 0.177935\tvalid_0's binary_logloss: 0.177935\n","[62]\tvalid_0's binary_logloss: 0.176335\tvalid_0's binary_logloss: 0.176335\n","[63]\tvalid_0's binary_logloss: 0.177703\tvalid_0's binary_logloss: 0.177703\n","[64]\tvalid_0's binary_logloss: 0.177072\tvalid_0's binary_logloss: 0.177072\n","[65]\tvalid_0's binary_logloss: 0.179378\tvalid_0's binary_logloss: 0.179378\n","[66]\tvalid_0's binary_logloss: 0.179497\tvalid_0's binary_logloss: 0.179497\n","[67]\tvalid_0's binary_logloss: 0.178183\tvalid_0's binary_logloss: 0.178183\n","[68]\tvalid_0's binary_logloss: 0.177896\tvalid_0's binary_logloss: 0.177896\n","[69]\tvalid_0's binary_logloss: 0.176544\tvalid_0's binary_logloss: 0.176544\n","[70]\tvalid_0's binary_logloss: 0.179593\tvalid_0's binary_logloss: 0.179593\n","[71]\tvalid_0's binary_logloss: 0.180264\tvalid_0's binary_logloss: 0.180264\n","[72]\tvalid_0's binary_logloss: 0.179142\tvalid_0's binary_logloss: 0.179142\n","[73]\tvalid_0's binary_logloss: 0.179372\tvalid_0's binary_logloss: 0.179372\n","[74]\tvalid_0's binary_logloss: 0.180671\tvalid_0's binary_logloss: 0.180671\n","[75]\tvalid_0's binary_logloss: 0.181006\tvalid_0's binary_logloss: 0.181006\n","[76]\tvalid_0's binary_logloss: 0.180837\tvalid_0's binary_logloss: 0.180837\n","[77]\tvalid_0's binary_logloss: 0.179753\tvalid_0's binary_logloss: 0.179753\n","[78]\tvalid_0's binary_logloss: 0.178535\tvalid_0's binary_logloss: 0.178535\n","[79]\tvalid_0's binary_logloss: 0.177768\tvalid_0's binary_logloss: 0.177768\n","[80]\tvalid_0's binary_logloss: 0.176634\tvalid_0's binary_logloss: 0.176634\n","[81]\tvalid_0's binary_logloss: 0.179132\tvalid_0's binary_logloss: 0.179132\n","[82]\tvalid_0's binary_logloss: 0.180418\tvalid_0's binary_logloss: 0.180418\n","[83]\tvalid_0's binary_logloss: 0.180412\tvalid_0's binary_logloss: 0.180412\n","[84]\tvalid_0's binary_logloss: 0.182996\tvalid_0's binary_logloss: 0.182996\n","[85]\tvalid_0's binary_logloss: 0.183015\tvalid_0's binary_logloss: 0.183015\n","[86]\tvalid_0's binary_logloss: 0.183001\tvalid_0's binary_logloss: 0.183001\n","[87]\tvalid_0's binary_logloss: 0.186434\tvalid_0's binary_logloss: 0.186434\n","[88]\tvalid_0's binary_logloss: 0.18692\tvalid_0's binary_logloss: 0.18692\n","[89]\tvalid_0's binary_logloss: 0.188795\tvalid_0's binary_logloss: 0.188795\n","[90]\tvalid_0's binary_logloss: 0.188522\tvalid_0's binary_logloss: 0.188522\n","[91]\tvalid_0's binary_logloss: 0.189248\tvalid_0's binary_logloss: 0.189248\n","[92]\tvalid_0's binary_logloss: 0.188207\tvalid_0's binary_logloss: 0.188207\n","[93]\tvalid_0's binary_logloss: 0.187303\tvalid_0's binary_logloss: 0.187303\n","[94]\tvalid_0's binary_logloss: 0.191187\tvalid_0's binary_logloss: 0.191187\n","[95]\tvalid_0's binary_logloss: 0.190131\tvalid_0's binary_logloss: 0.190131\n","[96]\tvalid_0's binary_logloss: 0.193149\tvalid_0's binary_logloss: 0.193149\n","[97]\tvalid_0's binary_logloss: 0.193841\tvalid_0's binary_logloss: 0.193841\n","[98]\tvalid_0's binary_logloss: 0.194369\tvalid_0's binary_logloss: 0.194369\n","[99]\tvalid_0's binary_logloss: 0.198002\tvalid_0's binary_logloss: 0.198002\n","[100]\tvalid_0's binary_logloss: 0.196817\tvalid_0's binary_logloss: 0.196817\n","[101]\tvalid_0's binary_logloss: 0.198075\tvalid_0's binary_logloss: 0.198075\n","[102]\tvalid_0's binary_logloss: 0.197112\tvalid_0's binary_logloss: 0.197112\n","[103]\tvalid_0's binary_logloss: 0.197974\tvalid_0's binary_logloss: 0.197974\n","[104]\tvalid_0's binary_logloss: 0.198988\tvalid_0's binary_logloss: 0.198988\n","[105]\tvalid_0's binary_logloss: 0.200624\tvalid_0's binary_logloss: 0.200624\n","[106]\tvalid_0's binary_logloss: 0.201354\tvalid_0's binary_logloss: 0.201354\n","[107]\tvalid_0's binary_logloss: 0.203268\tvalid_0's binary_logloss: 0.203268\n","[108]\tvalid_0's binary_logloss: 0.20232\tvalid_0's binary_logloss: 0.20232\n","[109]\tvalid_0's binary_logloss: 0.204995\tvalid_0's binary_logloss: 0.204995\n","[110]\tvalid_0's binary_logloss: 0.205616\tvalid_0's binary_logloss: 0.205616\n","[111]\tvalid_0's binary_logloss: 0.208434\tvalid_0's binary_logloss: 0.208434\n","[112]\tvalid_0's binary_logloss: 0.210362\tvalid_0's binary_logloss: 0.210362\n","[113]\tvalid_0's binary_logloss: 0.213181\tvalid_0's binary_logloss: 0.213181\n","[114]\tvalid_0's binary_logloss: 0.211509\tvalid_0's binary_logloss: 0.211509\n","[115]\tvalid_0's binary_logloss: 0.21102\tvalid_0's binary_logloss: 0.21102\n","[116]\tvalid_0's binary_logloss: 0.2109\tvalid_0's binary_logloss: 0.2109\n","[117]\tvalid_0's binary_logloss: 0.210673\tvalid_0's binary_logloss: 0.210673\n","[118]\tvalid_0's binary_logloss: 0.213351\tvalid_0's binary_logloss: 0.213351\n","[119]\tvalid_0's binary_logloss: 0.214342\tvalid_0's binary_logloss: 0.214342\n","[120]\tvalid_0's binary_logloss: 0.21729\tvalid_0's binary_logloss: 0.21729\n","[121]\tvalid_0's binary_logloss: 0.216636\tvalid_0's binary_logloss: 0.216636\n","[122]\tvalid_0's binary_logloss: 0.215613\tvalid_0's binary_logloss: 0.215613\n","[123]\tvalid_0's binary_logloss: 0.218125\tvalid_0's binary_logloss: 0.218125\n","[124]\tvalid_0's binary_logloss: 0.217402\tvalid_0's binary_logloss: 0.217402\n","[125]\tvalid_0's binary_logloss: 0.216723\tvalid_0's binary_logloss: 0.216723\n","[126]\tvalid_0's binary_logloss: 0.218308\tvalid_0's binary_logloss: 0.218308\n","[127]\tvalid_0's binary_logloss: 0.221872\tvalid_0's binary_logloss: 0.221872\n","[128]\tvalid_0's binary_logloss: 0.223218\tvalid_0's binary_logloss: 0.223218\n","[129]\tvalid_0's binary_logloss: 0.223951\tvalid_0's binary_logloss: 0.223951\n","[130]\tvalid_0's binary_logloss: 0.225266\tvalid_0's binary_logloss: 0.225266\n","[131]\tvalid_0's binary_logloss: 0.226742\tvalid_0's binary_logloss: 0.226742\n","[132]\tvalid_0's binary_logloss: 0.22728\tvalid_0's binary_logloss: 0.22728\n","[133]\tvalid_0's binary_logloss: 0.226776\tvalid_0's binary_logloss: 0.226776\n","[134]\tvalid_0's binary_logloss: 0.226722\tvalid_0's binary_logloss: 0.226722\n","[135]\tvalid_0's binary_logloss: 0.230367\tvalid_0's binary_logloss: 0.230367\n","Early stopping, best iteration is:\n","[35]\tvalid_0's binary_logloss: 0.163107\tvalid_0's binary_logloss: 0.163107\n","Test data prediction accuracy (LightGBM) : 0.921053\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZjjezdGewFHF","colab_type":"text"},"source":["# # Problem 6\n","Naive Bayes classifier.\n","- Scikit-learn의 Gaussian Naive Bayes classifier를 불러와 학습시키고, test데이터의 정확도를 출력하시오."]},{"cell_type":"code","metadata":{"id":"jHgCTjL7wFHF","colab_type":"code","outputId":"fb6429bd-badc-4bf8-a14b-6c31eeddc956","executionInfo":{"status":"ok","timestamp":1587823988087,"user_tz":-540,"elapsed":815,"user":{"displayName":"Seungmin Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrBDTQ8yuyAIB0J9i4gCDtr8Ku4cakCng55yF7=s64","userId":"12825424897417784138"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.naive_bayes import GaussianNB\n","\n","NB_model = None\n","accuracy = None\n","############# Put your code here ################\n","NB_model = GaussianNB()\n","NB_model.fit(X_train, Y_train)\n","test = NB_model.predict(X_test)\n","accuracy=0;\n","per=1/len(test)\n","for i in range(len(test)):\n","  if test[i]==Y_test[i]:\n","    accuracy+=per       \n","################################################# \n","print('Test data prediction accuracy (NaiveBayes) : %f'%accuracy)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Test data prediction accuracy (NaiveBayes) : 0.929825\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DcKTOj1jwFHI","colab_type":"text"},"source":["# # Problem 7\n","Ensemble classifier.\n","- 위의 6개의 모델(ID3, CART, Random Forest, XGBoost, LightGBM, Naive Bayes)을 이용하여 Voting(6개의 예측 label중 가장 많이 예측된 label을 최종 prediction label로 택하는것)방법으로 최종 label을 택한 뒤, 예측 정확도를 출력하시오.\n","- Scikit-learn의 VotingClassifier 패키지를 사용하여 작성.\n","- 위에서 학습시킨 모델 변수명 사용 가능."]},{"cell_type":"code","metadata":{"id":"isP0yhVjwFHI","colab_type":"code","outputId":"b722fdc0-89c6-4105-d131-5328411825d8","executionInfo":{"status":"ok","timestamp":1587823992045,"user_tz":-540,"elapsed":1494,"user":{"displayName":"Seungmin Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrBDTQ8yuyAIB0J9i4gCDtr8Ku4cakCng55yF7=s64","userId":"12825424897417784138"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.ensemble import VotingClassifier\n","\n","ensemble_classifier = None\n","accuracy = None\n","############# Put your code here ################\n","ensemble_classifier = VotingClassifier([\n","                        #('ID3',ID3_model),\n","                        ('CART', DecisionTreeClassifier(random_state=0)),\n","                        ('Random Forest', RandomForestClassifier(random_state=0)),\n","                        ('XGBoost',xgb.XGBClassifier()),\n","                        ('LightGBM',lgb.LGBMClassifier(n_estimators=200)),\n","                        ('Naive Bayes',GaussianNB())\n","                        ])\n","\n","ensemble_classifier.fit(X_train,Y_train);\n","accuracy=ensemble_classifier.score(X_test, Y_test)\n","################################################# \n","print('Test data prediction accuracy (Ensemble) : %f'%accuracy)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Test data prediction accuracy (Ensemble) : 0.956140\n"],"name":"stdout"}]}]}